{
 "cells": [
  {
   "cell_type": "raw",
   "id": "507ca1c4",
   "metadata": {},
   "source": [
    "---\n",
    "jupytext:\n",
    "  formats: md:myst\n",
    "  text_representation:\n",
    "    extension: .md\n",
    "    format_name: myst\n",
    "    format_version: 0.13\n",
    "    jupytext_version: 1.14.0\n",
    "kernelspec:\n",
    "  display_name: Python 3 (ipykernel)\n",
    "  language: python\n",
    "  name: ipython3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50494b4",
   "metadata": {},
   "source": [
    "Simple Usage Example\n",
    "====================\n",
    "\n",
    "In this page, we provide a simple example of using the Gurobi Machine Learning package.\n",
    "\n",
    "The example is entirely abstract. Its aim is only to illustrate the basic functionalities of the\n",
    "package in the most simple way. For some more realistic applications, please refer to the notebooks.\n",
    "\n",
    "Before proceeding to the example itself, we need to import a number of packages.\n",
    "Here, we will use `scikit-learn` to train regression models. We generate random data for the\n",
    "regression using the :external+sklearn:py:func:`sklearn.datasets.make_regression`. For the regression model, we use a neural network :external:py:class:`sklearn.neural_network.MLPRegressor`, import the corresponding\n",
    "objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82efe09",
   "metadata": {},
   "source": [
    "Certainly, we also need `gurobipy` to build an optimization model and from the `gurobi_ml` package we need the `add_predictor_constr`\n",
    "function. We will also need `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41561fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfc5a2",
   "metadata": {},
   "source": [
    "We start by building artificial data for training our regressions. To do so, we use _make_regression_ to obtain\n",
    "data with 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_features=10, noise=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07f260",
   "metadata": {},
   "source": [
    "Now, create the _MLPRegressor_ object and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPRegressor([20]*2, max_iter=10000, random_state=1)\n",
    "\n",
    "nn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52deedc6",
   "metadata": {},
   "source": [
    "We now turn to the optimization model. In the spirit of adversarial machine learning examples, we use some training examples.\n",
    "We pick $n$ training examples randomly. For each of the examples, we want to find an input that is in a small neighborhood of it that leads to the output that is closer to $0$ with the regression.\n",
    "\n",
    "Denoting by $X^E$ our set of examples and by $g$ the prediction function of our regression model, our optimization problem reads:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\min \\sum_{i=1}^5 y_i^2 \\\\\n",
    "&\\text{s.t.:}\\\\\n",
    "&y_i = g(X_i) & & i = 1, \\ldots, n,\\\\\n",
    "&X^E - \\delta \\leq X \\leq X^E + \\delta,\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $X$ is a matrix of variables of dimension $n \\times 10$ (the number of examples we consider and number of features in the regression respectively), $y$ is a vector of free (unbounded) variables and $\\delta$ a small positive constant.\n",
    "\n",
    "First, let's pick randomly 2 training examples using `numpy`, and create our `gurobipy` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "index = np.random.choice(X.shape[0], n, replace=False)\n",
    "X_examples = X[index, :]\n",
    "y_examples = y[index]\n",
    "\n",
    "m = gp.Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa8bdf",
   "metadata": {},
   "source": [
    "Our only decision variables in this case, are the five inputs and outputs for the regression. We use `gurobipy.MVar` matrix variables that are most convenient in this case.\n",
    "\n",
    "The input variables have the same shape as `X_examples`. Their lower bound is `X_examples - delta` and their upper bound `X_examples + delta`.\n",
    "\n",
    "The output variables have the shape of `y_examples` and are unbounded. By default, in Gurobi variables are non-negative, we therefore need to set an infinite lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = m.addMVar(X_examples.shape, lb=X_examples-0.2, ub=X_examples+0.2)\n",
    "output_vars = m.addMVar(y_examples.shape, lb=-gp.GRB.INFINITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1565a0",
   "metadata": {},
   "source": [
    "The constraints linking `input_vars` and `output_vars` can now be added with the function `add_predictor_constr`.\n",
    "\n",
    "Note that because of the shape of the variables this will add the 5 different constraints.\n",
    "\n",
    "The function returns a modeling object that we can use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(m, nn, input_vars, output_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfbf93",
   "metadata": {},
   "source": [
    "The member function `print_stats` of the modeling object outputs the details of the regression model that was added to the Gurobi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f33da9a",
   "metadata": {},
   "source": [
    "To finish the model, we set the objective, and then we can optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setObjective(output_vars@output_vars, gp.GRB.MINIMIZE)\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc7d54",
   "metadata": {},
   "source": [
    "The function `get_error` is useful to check that the solution computed by Gurobi is correct with respect to the regression model we use.\n",
    "\n",
    "Let $(\\bar X, \\bar y)$ be the values of the input and output variables in the computed solution. The function returns $g(\\bar X) - y$ using the original regression (in this case the `scikit-learn`) object.\n",
    "\n",
    "Normally, all values should be small and below Gurobi's tolerances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.get_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ef7b2",
   "metadata": {},
   "source": [
    "Finally, we can look at the computed values for the output variables and compare them with the original targets values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vars.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_examples"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "code-cell",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
